# Project 2: Learning from Imbalanced Datasets (Supervised and Unsupervised Learning)
## CE888
### Arely Aceves Compean
### 1900968

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score, accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import RandomForestClassifier


# Returns the score of the selected measure for methods and performs 
# cross-validation internally, it receives a list of ground data and 
# predictions and displays the average and std deviation of each measure
def scoring_baseline(X, y, clf, model, measure='f1'):
    scores_a = cross_val_score(clf, X, y, cv=10, scoring = 'accuracy')
    scores_p = cross_val_score(clf, X, y, cv=10, scoring = 'precision')
    scores_r = cross_val_score(clf, X, y, cv=10, scoring = 'recall')
    scores_f = cross_val_score(clf, X, y, cv=10, scoring = 'f1')
    print("SCORES FOR MODEL ", model.upper(), ":", sep='')
    print("ACCURACY: %0.4f +/- %0.4f" % (scores_a.mean(), scores_a.std()))
    print("PRECISION: %0.4f +/- %0.4f" % (scores_p.mean(), scores_p.std()))
    print("RECALL: %0.4f +/- %0.4f" % (scores_r.mean(), scores_r.std()))
    print("F1: %0.4f +/- %0.4f" % (scores_f.mean(), scores_f.std()))
    if measure == 'accuracy':
        return scores_a
    if measure == 'precision':
        return scores_p
    if measure == 'recall':
        return scores_r
    if measure == 'f1':
        return scores_f

# Displays the Silhouette and elbow graphs, receives user input 
# and returns the optimal k and trained kMeans clusterer
def silhouette_elbow_cluster_selection(X, y):
    Sum_of_squared_distances = []
    silhouette = []
    K = range(2,15)
    max_score = -1
    max_k = -1
    # Kmeans trained with 14 possible k
    for k in K:
        km = KMeans(n_clusters=k).fit(X)
        Sum_of_squared_distances.append(km.inertia_)
        silhouette.append(silhouette_score(X, km.labels_, metric='euclidean'))
        
    # Silhouette graph
    plt.plot(K, silhouette, 'bx-')
    plt.xlabel('k')
    plt.ylabel('silhouette_score')
    plt.title('Silhouette Method For Optimal k')
    plt.show()

    # User input
    input_silhouette = int(input("Please enter the selected number of clusters for the silhouette graph:\n"))

    # Elbow graph
    plt.plot(K, Sum_of_squared_distances, 'bx-')
    plt.xlabel('k')
    plt.ylabel('Sum_of_squared_distances')
    plt.title('Elbow Method For Optimal k')
    plt.show()
    
    # User input
    input_elbow = int(input("Please enter the selected number of clusters for the elbow graph:\n"))
    
    # Upper and Lower bounds to test
    min_test_k = input_elbow if input_elbow < input_silhouette else input_silhouette
    max_test_k = input_elbow if input_elbow > input_silhouette else input_silhouette
    
    final_k = 0
    final_score = 0
    final_clustering = KMeans(n_clusters=min_test_k).fit(X)
    
    # Selecting optimal k according to f1 score
    for i in range(min_test_k, max_test_k + 1):
        km_test = KMeans(n_clusters=i).fit(X)
        score = f1_score(km_test.labels_, y, average='weighted')
        if score > final_score:
            final_k = i
            final_clustering = km_test
            final_score = score
            
    print('Best performing clustering f1-score is:', final_score,  "for n_clusters =", final_k)

    return final_k, final_clustering

# Returns a list of trained random forest classifiers/predictions per cluster
def cluster_training(X, y, k, chosen_km):
    true = np.zeros(k)
    false = np.zeros(k)
    X_cluster_list = [[] for i in range(k)]
    y_cluster_list = [[] for i in range(k)]
    result_list = [None for i in range(k)]

    for i in range(len(chosen_km.labels_)):
        true[chosen_km.labels_[i]] += 1 if y[i] == 1 else 0 # Count 1 labels per cluster
        false[chosen_km.labels_[i]] += 1 if y[i] == 0 else 0 # Count 0 labels per cluster
        X_cluster_list[chosen_km.labels_[i]].append(X[i]) # Stores feature arrays per cluster
        y_cluster_list[chosen_km.labels_[i]].append(y[i]) # Stores labels per cluster

    # Stores selected prediction for clusters with only one class
    for i in range(k):
        if true[i] == 0:
            result_list[i] = 1
        if false[i] == 0:
            result_list[i] = 0

    # Stores trained random forest classifier for clusters with more than one class
    for i in range(k):
        if result_list[i] == None:
            #train a random forest classifier
            clf = RandomForestClassifier(random_state=0, max_depth=2)
            #save it to result_list
            result_list[i] = clf.fit(X_cluster_list[i], y_cluster_list[i])
    
    return result_list

# Returns a list of predictions generated by the classifier of the predicted cluster
def cluster_testing(X, chosen_km, clfs):
    cluster_labels = chosen_km.predict(X) # Predict cluster of each example
    y_predicted = []

    # PRedict label according to each cluster
    for index, label in enumerate(cluster_labels):
        if clfs[label] == 0:
            y_predicted.append(0)
        elif clfs[label] == 1:
            y_predicted.append(1)
        else:
            y_predicted.append(clfs[label].predict(X[index].reshape(1, -1))[0])

    return y_predicted

# Returns the score of the selected measure for methods with external 
# cross-validation, it receives a list of ground data and predictions 
# and displays the average and std deviation of each measure
def scoring(y_true, y_pred, measure='f1'):
    scores_a = np.array([])
    scores_p = np.array([])
    scores_r = np.array([])
    scores_f = np.array([])

    for i in range(len(y_true)):
        scores_a = np.append(scores_a, accuracy_score(np.array(y_pred[i]), y_true[i]))
        scores_p = np.append(scores_p, precision_score(np.array(y_pred[i]), y_true[i], average='weighted'))
        scores_r = np.append(scores_r, recall_score(np.array(y_pred[i]), y_true[i], average='weighted'))
        scores_f = np.append(scores_f, f1_score(np.array(y_pred[i]), y_true[i], average='weighted'))
    
    print("SCORES FOR MODEL:")
    print("ACCURACY: %0.4f +/- %0.4f" % (scores_a.mean(), scores_a.std()))
    print("PRECISION: %0.4f +/- %0.4f" % (scores_p.mean(), scores_p.std()))
    print("RECALL: %0.4f +/- %0.4f" % (scores_r.mean(), scores_r.std()))
    print("F1: %0.4f +/- %0.4f" % (scores_f.mean(), scores_f.std()))
    
    if measure == 'accuracy':
        return scores_a
    if measure == 'precision':
        return scores_p
    if measure == 'recall':
        return scores_r
    if measure == 'f1':
        return scores_f

# Displays boxplots
def boxplot(data, title):
    fig1, ax1 = plt.subplots()
    ax1.set_title(title)
    ax1.set_xticklabels(['F1'])
    ax1.boxplot(data)
    plt.show()

# Displays boxplot without outliers
def noOutliers_boxplot(data, title):
    fig1, ax1 = plt.subplots()
    ax1.set_title(title)
    ax1.set_xticklabels(['F1'])
    ax1.boxplot(data, showfliers=False)
    plt.show()